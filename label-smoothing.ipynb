{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "caa0a8ad",
   "metadata": {},
   "source": [
    "## Label Smoothing\n",
    "\n",
    "Label smoothing is a lesser-talked regularisation technique that elegantly addresses this issue.\n",
    "\n",
    "We intentionally reduce the probability mass of the true class slightly.\n",
    "The reduced probability mass is uniformly distributed to all other classes.\n",
    "\n",
    "As asking the model to be “less overconfident” during training and prediction while still attempting to make accurate predictions.\n",
    "\n",
    "### When not to use label smoothing?\n",
    "\n",
    "if you only care about getting the final prediction correct and improving generalization, label smoothing will be a pretty handy technique.\n",
    "\n",
    "However, I wouldn’t recommend utilizing it if you care about:\n",
    "1. Getting the prediction correct.\n",
    "2. And understanding the model’s confidence in generating a prediction.\n",
    "\n",
    "This is because as we discussed above, label smoothing guides the model to become “less overconfident” about its predictions.\n",
    "Thus, we typically notice a drop in the confidence values for every prediction\n",
    "\n",
    "A Comment + A Comment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61eb6572",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b99f7797",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-06T10:56:55.918637Z",
     "start_time": "2023-11-06T10:56:53.337400Z"
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from skorch import NeuralNetClassifier\n",
    "from time import time\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40b336fc",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0f314172",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-06T10:56:55.977241Z",
     "start_time": "2023-11-06T10:56:55.920429Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz to ./data/FashionMNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 26421880/26421880 [00:03<00:00, 7039425.68it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/FashionMNIST/raw/train-images-idx3-ubyte.gz to ./data/FashionMNIST/raw\n",
      "\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz to ./data/FashionMNIST/raw/train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 29515/29515 [00:00<00:00, 156468.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/FashionMNIST/raw/train-labels-idx1-ubyte.gz to ./data/FashionMNIST/raw\n",
      "\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz to ./data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4422102/4422102 [00:01<00:00, 3061159.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz to ./data/FashionMNIST/raw\n",
      "\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz to ./data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5148/5148 [00:00<00:00, 1276516.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz to ./data/FashionMNIST/raw\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Define data transformations\n",
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\n",
    "\n",
    "# Load the Fashion MNIST dataset for both train and test sets\n",
    "train_dataset = torchvision.datasets.FashionMNIST(root='./data', train=True, transform=transform, download=True)\n",
    "test_dataset = torchvision.datasets.FashionMNIST(root='./data', train=False, transform=transform, download=True)\n",
    "\n",
    "# Define batch sizes for train and test data loaders\n",
    "batch_size = 64\n",
    "\n",
    "# Create data loaders for train and test sets\n",
    "trainloader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "testloader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d98b00e",
   "metadata": {},
   "source": [
    "## Set seeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9790628c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-06T10:56:57.334104Z",
     "start_time": "2023-11-06T10:56:57.300992Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x13921f910>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(20)\n",
    "torch.manual_seed(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65571258",
   "metadata": {},
   "source": [
    "## Define Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "00c3ad22",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-06T10:56:58.122301Z",
     "start_time": "2023-11-06T10:56:58.115964Z"
    }
   },
   "outputs": [],
   "source": [
    "# Define a simple teacher neural network with 4 fully connected layers\n",
    "class SimpleNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleNet, self).__init__()\n",
    "        self.fc1 = nn.Linear(28 * 28, 512)\n",
    "        self.fc2 = nn.Linear(512, 256)\n",
    "        self.fc3 = nn.Linear(256, 128)\n",
    "        self.fc4 = nn.Linear(128, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x1 = torch.relu(self.fc1(x))\n",
    "        x2 = torch.relu(self.fc2(x1))\n",
    "        x3 = torch.relu(self.fc3(x2))\n",
    "        x4 = self.fc4(x3)\n",
    "        return x1, x2, x3, x4  # Return intermediate feature activations for activation pruning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77f06eaf",
   "metadata": {},
   "source": [
    "## Test evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f7c94415",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-06T10:56:59.599336Z",
     "start_time": "2023-11-06T10:56:59.594962Z"
    }
   },
   "outputs": [],
   "source": [
    "def evaluate(model):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for data in testloader:\n",
    "            inputs, labels = data\n",
    "            outputs = model(inputs)[-1] # use last element returned by forward function\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    return correct / total"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0de367f",
   "metadata": {},
   "source": [
    "## Without label Smoothing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d8aba586",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-06T10:58:46.321998Z",
     "start_time": "2023-11-06T10:57:05.474313Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 0.5, Accuracy: 84.90%\n",
      "Epoch 2, Loss: 0.37, Accuracy: 85.73%\n",
      "Epoch 3, Loss: 0.33, Accuracy: 86.78%\n",
      "Epoch 4, Loss: 0.31, Accuracy: 87.45%\n",
      "Epoch 5, Loss: 0.29, Accuracy: 87.46%\n",
      "Epoch 6, Loss: 0.27, Accuracy: 87.28%\n",
      "Epoch 7, Loss: 0.26, Accuracy: 86.80%\n",
      "Epoch 8, Loss: 0.25, Accuracy: 87.62%\n",
      "Epoch 9, Loss: 0.23, Accuracy: 88.46%\n",
      "Epoch 10, Loss: 0.22, Accuracy: 88.79%\n",
      "Epoch 11, Loss: 0.21, Accuracy: 88.21%\n",
      "Epoch 12, Loss: 0.2, Accuracy: 88.14%\n",
      "Epoch 13, Loss: 0.19, Accuracy: 88.81%\n",
      "Epoch 14, Loss: 0.18, Accuracy: 89.17%\n",
      "Epoch 15, Loss: 0.17, Accuracy: 88.81%\n",
      "Epoch 16, Loss: 0.17, Accuracy: 89.00%\n",
      "Epoch 17, Loss: 0.16, Accuracy: 88.54%\n",
      "Epoch 18, Loss: 0.15, Accuracy: 89.12%\n",
      "Epoch 19, Loss: 0.15, Accuracy: 88.97%\n",
      "Epoch 20, Loss: 0.14, Accuracy: 88.84%\n"
     ]
    }
   ],
   "source": [
    "net = SimpleNet()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.001)\n",
    "\n",
    "for epoch in range(20):\n",
    "    net.train()\n",
    "    running_loss = 0.0\n",
    "    \n",
    "    for data in trainloader:\n",
    "        inputs, labels = data\n",
    "        optimizer.zero_grad()\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs[-1], labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        \n",
    "    accuracy = evaluate(net)\n",
    "        \n",
    "    print(f\"Epoch {epoch + 1}, Loss: {round(running_loss / len(trainloader), 2)}, Accuracy: {accuracy * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca016796",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-06T10:59:19.255954Z",
     "start_time": "2023-11-06T10:59:18.801292Z"
    }
   },
   "source": [
    "### Output probability on a sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "03eadaa2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-06T10:59:20.855885Z",
     "start_time": "2023-11-06T10:59:20.815268Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/0l/p7lzlqxn44b036b_3ykx4tlr0000gn/T/ipykernel_33148/2955729995.py:7: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  F.softmax(net(inputs[0])[-1])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[5.8588e-03, 7.4752e-04, 3.6302e-04, 9.9173e-01, 1.2088e-05, 1.4675e-08,\n",
       "         1.2671e-03, 2.2036e-14, 2.3719e-05, 1.0715e-11]],\n",
       "       grad_fn=<SoftmaxBackward0>)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "        for data in testloader:\n",
    "            inputs, labels = data\n",
    "\n",
    "F.softmax(net(inputs[0])[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5559eb2d",
   "metadata": {},
   "source": [
    "## With Label Smoothing\n",
    "\n",
    "Restart the kernel before executing the cell below. This time, don't run the \"Without label Smoothing\" cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "59d8d511",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-06T08:39:10.481632Z",
     "start_time": "2023-11-06T08:37:26.456943Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 1.19, Accuracy: 84.17%\n",
      "Epoch 2, Loss: 1.1, Accuracy: 86.38%\n",
      "Epoch 3, Loss: 1.08, Accuracy: 86.80%\n",
      "Epoch 4, Loss: 1.06, Accuracy: 87.46%\n",
      "Epoch 5, Loss: 1.05, Accuracy: 87.47%\n",
      "Epoch 6, Loss: 1.04, Accuracy: 88.16%\n",
      "Epoch 7, Loss: 1.03, Accuracy: 88.47%\n",
      "Epoch 8, Loss: 1.02, Accuracy: 88.73%\n",
      "Epoch 9, Loss: 1.01, Accuracy: 88.46%\n",
      "Epoch 10, Loss: 1.01, Accuracy: 88.56%\n",
      "Epoch 11, Loss: 1.0, Accuracy: 88.98%\n",
      "Epoch 12, Loss: 1.0, Accuracy: 88.51%\n",
      "Epoch 13, Loss: 0.99, Accuracy: 88.80%\n",
      "Epoch 14, Loss: 0.98, Accuracy: 89.41%\n",
      "Epoch 15, Loss: 0.98, Accuracy: 88.60%\n",
      "Epoch 16, Loss: 0.97, Accuracy: 89.34%\n",
      "Epoch 17, Loss: 0.97, Accuracy: 88.83%\n",
      "Epoch 18, Loss: 0.96, Accuracy: 88.78%\n",
      "Epoch 19, Loss: 0.96, Accuracy: 89.07%\n",
      "Epoch 20, Loss: 0.96, Accuracy: 89.29%\n"
     ]
    }
   ],
   "source": [
    "net = SimpleNet()\n",
    "criterion = nn.CrossEntropyLoss(label_smoothing = 0.2)\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.001)\n",
    "\n",
    "for epoch in range(20):\n",
    "    net.train()\n",
    "    running_loss = 0.0\n",
    "    \n",
    "    for data in trainloader:\n",
    "        inputs, labels = data\n",
    "        optimizer.zero_grad()\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs[-1], labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        \n",
    "    accuracy = evaluate(net)\n",
    "        \n",
    "    print(f\"Epoch {epoch + 1}, Loss: {round(running_loss / len(trainloader), 2)}, Accuracy: {accuracy * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bc16276",
   "metadata": {},
   "source": [
    "### Output probability on a sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c151fda4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-06T10:56:44.083805Z",
     "start_time": "2023-11-06T10:56:44.070685Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/0l/p7lzlqxn44b036b_3ykx4tlr0000gn/T/ipykernel_33148/2955729995.py:7: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  F.softmax(net(inputs[0])[-1])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[0.0375, 0.0308, 0.0264, 0.6425, 0.0349, 0.0293, 0.1042, 0.0259, 0.0412,\n",
       "         0.0274]], grad_fn=<SoftmaxBackward0>)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "        for data in testloader:\n",
    "            inputs, labels = data\n",
    "\n",
    "F.softmax(net(inputs[0])[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
