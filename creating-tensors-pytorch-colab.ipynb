{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMP/GDyV0Ik1dea1+y9vS9e",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MonuSingh16/code-deep-learning/blob/main/creating-tensors-pytorch-colab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##  Creating Tensors on PyTorch\n",
        "\n",
        "Despite its popularity, I have noticed that many PyTorch users don’t create tensors optimally, specifically when using GPUs for model training.\n",
        "\n",
        "As a result, it drastically increases memory usage, which, in turn, kills the training process.\n",
        "\n",
        "```\n",
        "import torch\n",
        "tensors = torch.rand(100, 100).cuda()\n",
        "```\n",
        "\n",
        "The problem is that it first creates a tensor on the CPU, and then PyTorch transfers it to the GPU.\n",
        "This is slow because we unnecessarily created a tensor on the CPU, which was unnecessary.\n",
        "\n",
        "```\n",
        "import torch\n",
        "tensors = torch.rand(100, 100, device=torch.device('cuda:0'))\n",
        "```"
      ],
      "metadata": {
        "id": "ACm3raDbUCk_"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "KOP4k4adUBYQ",
        "outputId": "90b1f4cf-ed50-4cb5-dc8f-d0bc7d54e39a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'cuda'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "import torch\n",
        "\n",
        "#device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "#device"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%timeit torch.rand(500, 500).cuda()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wAclrqFoUGVw",
        "outputId": "873107a5-e83a-46dd-f3b3-4f90db9d79ab"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.96 ms ± 95.5 µs per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%timeit torch.rand(500, 500, device=torch.device('cuda:0'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D8EnzjLsUmHR",
        "outputId": "391f2326-738f-4595-f205-0cad5de7b063"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "13.7 µs ± 2.63 µs per loop (mean ± std. dev. of 7 runs, 100000 loops each)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "KtCajGCSUt4i"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}